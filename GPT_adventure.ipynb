{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvOXIy8xWzI4Ntk3KXbgF6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NelsenYoung/GPT_adventure/blob/main/GPT_adventure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u7k9YPX_IuI",
        "outputId": "a840c78e-a2fd-44e0-fcb2-0b06025f3144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-06 21:41:43--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2026-01-06 21:41:43 (18.6 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Setup of the boilerplate\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"input.txt\") as f:\n",
        "  text = f.read()\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "408cIMoh_rnS",
        "outputId": "d16fe01e-db25-4e44-8b06-0db3b690d04d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6yvrbPT13yY",
        "outputId": "92aad6e9-fdd3-4c5a-c613-894d955f0c54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gnQEfDWMt4i",
        "outputId": "54916d6d-b00f-4e2a-9164-ebdc00ed3ac6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the dataset\n",
        "chars = sorted(list(set(text)))\n",
        "chars.insert(0, ']')\n",
        "stoi = {s:i for i, s in enumerate(chars)}\n",
        "itos = {i:s for i, s in enumerate(chars)}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fsG4uVbthNx5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the character-wise dataset\n",
        "block_size = 8\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "# For each token, grab a block\n",
        "for i in range(len(text) - (block_size)):\n",
        "  xs = text[i:(i+block_size)]\n",
        "  ys = text[i+block_size]\n",
        "\n",
        "  # Encode the block\n",
        "  xs = [stoi[i] for i in xs]\n",
        "  ys = [stoi[i] for i in ys]\n",
        "\n",
        "  X.append(xs)\n",
        "  Y += ys\n",
        "  if i % 100000 == 0:\n",
        "    print(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqkrAtPEADOY",
        "outputId": "2524149d-6d34-4413-bdf0-a668e31bb1f3",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n",
            "1000000\n",
            "1100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X), len(Y))\n",
        "num_examples = len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96adEfJzQVJV",
        "outputId": "648d8301-63bd-46eb-b76d-b5cef6711d8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115386 1115386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "id": "7if8a3uXO6H5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into test and train splits\n",
        "test_train_split = 8\n",
        "split = (num_examples // 10) * test_train_split\n",
        "X_train = X[:split]\n",
        "Y_train = Y[:split]\n",
        "X_test = X[split:]\n",
        "Y_test = Y[split:]"
      ],
      "metadata": {
        "id": "UGNwRHxFSase"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For mini batching, all we want to do is grab 32 random numbers in range 0 and train examlpes size\n",
        "batch_size = 32\n",
        "train_data_size = X_train.shape[0]\n",
        "idxs = torch.randint(train_data_size, (batch_size,))\n",
        "x = X_train[idxs]\n",
        "y = Y_train[idxs]\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P09P92r5cYY7",
        "outputId": "cb9eb594-92d9-417a-db40-c3b87e3a254d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(text))\n",
        "emb_dims = 12\n",
        "num_hidden = 200\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Embedding(num_classes, emb_dims),\n",
        "    torch.nn.Flatten(1),\n",
        "    torch.nn.Linear(block_size * emb_dims, num_hidden),\n",
        "    torch.nn.Tanh(),\n",
        "    torch.nn.Linear(num_hidden, num_classes)\n",
        ")\n",
        "\n",
        "logits = model.forward(x)\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izGod9EkSjrn",
        "outputId": "c092f3b1-8f7e-412a-b401-21682f0fec1f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 65])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Loss\n",
        "loss = F.cross_entropy(logits, y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRr1O9oGUsRZ",
        "outputId": "abf5aa57-b3bb-4496-e492-311cdebd6fd3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.2140, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backtrack\n",
        "loss.backward()\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "optim.step()"
      ],
      "metadata": {
        "id": "cXxFC9XnQdSS"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}