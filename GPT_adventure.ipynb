{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOL8abmO13RrAi1UdX7xsHr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NelsenYoung/GPT_adventure/blob/main/GPT_adventure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u7k9YPX_IuI",
        "outputId": "73060604-f1d6-4f7e-eacf-a2719ae32576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-04 01:05:21--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2026-01-04 01:05:21 (35.8 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Setup of the boilerplate\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"input.txt\") as f:\n",
        "  text = f.read()\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "408cIMoh_rnS",
        "outputId": "9bb47ec3-fef6-4b16-e43b-71d64fb9004e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6yvrbPT13yY",
        "outputId": "7b681cf2-2bed-4cb6-e035-128781ac8758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the dataset\n",
        "chars = sorted(list(set(text)))\n",
        "chars.insert(0, ']')\n",
        "stoi = {s:i for i, s in enumerate(chars)}\n",
        "itos = {i:s for i, s in enumerate(chars)}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fsG4uVbthNx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the character-wise dataset\n",
        "block_size = 8\n",
        "\n",
        "X = torch.zeros(0, block_size)\n",
        "Y = torch.zeros(block_size + 1)\n",
        "# For each token, grab a block\n",
        "for i in range(len(text[:10000]) - (block_size - 1)):\n",
        "  xs = text[i:(i+block_size)]\n",
        "  ys = text[i:(i+block_size+1)]\n",
        "  # print(f'xs: {xs}, ys: {ys}')\n",
        "\n",
        "  # Encode the block\n",
        "  xs = [stoi[i] for i in xs]\n",
        "  ys = [stoi[i] for i in ys]\n",
        "  # ys = [xs[0]] + ys\n",
        "\n",
        "  # Create examples within the block\n",
        "  x = [stoi[']'] for _ in range(block_size)]\n",
        "  y = torch.tensor(ys)\n",
        "\n",
        "  for i in range(block_size):\n",
        "    x_t = torch.tensor(x)\n",
        "    x_t = x_t.view(1, -1)\n",
        "    X = torch.cat((X, x_t), 0)\n",
        "    x.append(xs[i])\n",
        "    x = x[1:]\n",
        "\n",
        "  x_t = torch.tensor(x)\n",
        "  x_t = x_t.view(1, -1)\n",
        "  X = torch.cat((X, x_t), 0)\n",
        "  Y = torch.cat((Y, y), 0)\n",
        "\n",
        "X.shape\n",
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqkrAtPEADOY",
        "outputId": "bbb84903-1c9a-4270-fc9a-e3763cb44c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([89946])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPbWrVBvovmV",
        "outputId": "fb6ceb94-07f9-4ea0-d77e-62e46986efc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([89937, 8]), torch.Size([89946]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}