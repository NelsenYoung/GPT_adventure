{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiuZUyJy2utYMPM9XgpYxC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NelsenYoung/GPT_adventure/blob/main/GPT_adventure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u7k9YPX_IuI",
        "outputId": "a840c78e-a2fd-44e0-fcb2-0b06025f3144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-06 21:41:43--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2026-01-06 21:41:43 (18.6 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Setup of the boilerplate\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"input.txt\") as f:\n",
        "  text = f.read()\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "408cIMoh_rnS",
        "outputId": "5a7a294a-581e-439b-b99f-e4d57b76f6db"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gnQEfDWMt4i",
        "outputId": "72148e0a-cad8-48bb-bd01-96e99eff7424"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the dataset\n",
        "chars = sorted(list(set(text)))\n",
        "stoi = {s:i for i, s in enumerate(chars)}\n",
        "itos = {i:s for i, s in enumerate(chars)}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fsG4uVbthNx5"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the character-wise dataset\n",
        "block_size = 8\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "# For each token, grab a block\n",
        "for i in range(len(text) - (block_size)):\n",
        "  xs = text[i:(i+block_size)]\n",
        "  ys = text[i+block_size]\n",
        "\n",
        "  # Encode the block\n",
        "  xs = [stoi[i] for i in xs]\n",
        "  ys = [stoi[i] for i in ys]\n",
        "\n",
        "  X.append(xs)\n",
        "  Y += ys\n",
        "  if i % 100000 == 0:\n",
        "    print(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqkrAtPEADOY",
        "outputId": "c171c821-91c9-4215-d76c-8d4a9f4465f3",
        "collapsed": true
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n",
            "1000000\n",
            "1100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X), len(Y))\n",
        "num_examples = len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96adEfJzQVJV",
        "outputId": "e2391460-fff2-49df-db86-9932c2d5d5af"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115386 1115386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "id": "7if8a3uXO6H5"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into test and train splits\n",
        "test_train_split = 8\n",
        "split = (num_examples // 10) * test_train_split\n",
        "X_train = X[:split]\n",
        "Y_train = Y[:split]\n",
        "X_test = X[split:]\n",
        "Y_test = Y[split:]"
      ],
      "metadata": {
        "id": "UGNwRHxFSase"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(text))\n",
        "emb_dims = 12\n",
        "num_hidden = 200\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Embedding(num_classes, emb_dims),\n",
        "    torch.nn.Flatten(1),\n",
        "    torch.nn.Linear(block_size * emb_dims, num_hidden),\n",
        "    torch.nn.Tanh(),\n",
        "    torch.nn.Linear(num_hidden, num_classes)\n",
        ")"
      ],
      "metadata": {
        "id": "izGod9EkSjrn"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100000\n",
        "lr = 1e-3\n",
        "momentum = 0.9\n",
        "batch_size = 32\n",
        "train_data_size = X_train.shape[0]\n",
        "optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "for i in range(epochs):\n",
        "  # mini batch\n",
        "  idxs = torch.randint(train_data_size, (batch_size,))\n",
        "  x = X_train[idxs]\n",
        "  y = Y_train[idxs]\n",
        "\n",
        "  # forward pass\n",
        "  logits = model.forward(x)\n",
        "\n",
        "  # backward pass\n",
        "  optim.zero_grad()\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  if i % 10000 == 0:\n",
        "    print(loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpxArI7saH8N",
        "outputId": "343a6483-a34a-4933-a629-05b789926e5d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.1951, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1490, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3609, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7269, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8157, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2011, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7788, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9994, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7540, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7708, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    }
  ]
}